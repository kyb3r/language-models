{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/names.txt\") as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "chars = [\".\", \"@\"] + sorted(list(set(''.join(words))))\n",
    "vocab_size = len(chars) # 28 in this case\n",
    "\n",
    "str_to_idx = {s: i for i, s in enumerate(chars)}\n",
    "idx_to_str = {i: s for s, i in str_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  6, 14, 14,  2,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [ 0, 16, 13, 10, 23, 10,  2,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [ 0,  2, 23,  2,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for word in words:\n",
    "    sequence = [0] + [str_to_idx[c] for c in word] + [0]\n",
    "    dataset.append(torch.tensor(sequence))\n",
    "\n",
    "dataset = pad_sequence(dataset, batch_first=True, padding_value=1)\n",
    "\n",
    "print(dataset[:3])\n",
    "\n",
    "dataloader = DataLoader(TensorDataset(dataset), batch_size=250, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model architecture\n",
    "\n",
    "In this case, we will be making an RNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_size=500, embedding_size=20):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.character_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        # self.i2h = nn.Linear(embedding_size+hidden_size, hidden_size)\n",
    "        self.i2h = nn.Sequential(\n",
    "            nn.Linear(embedding_size+hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # self.i2o = nn.Linear(embedding_size+hidden_size, vocab_size)\n",
    "        self.i2o = nn.Sequential(\n",
    "            nn.Linear(embedding_size+hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, vocab_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = self.character_embeddings(input) \n",
    "        combined = torch.cat([input, hidden], 1)\n",
    "        # print(combined.shape)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden(self, batch_size=1):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 55.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.0670150577472581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 57.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.9714282862972646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 61.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.9381130730071369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 61.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.915664292647129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:01<00:00, 66.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.8989495274958432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 58.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.8845269621476507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 61.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 0.8703676145131077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 0.8592433383718522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 63.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 0.8497945219133559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:01<00:00, 65.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 0.8399591883846872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 59.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.8316501682739401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 62.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss: 0.8234349000378339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 62.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss: 0.8163020048708264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 56.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss: 0.809380215856988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 63.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss: 0.8022316807717091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 60.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss: 0.7965765284044742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 62.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss: 0.7905375503206691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 55.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss: 0.7848070469740442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 61.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss: 0.7803334804872742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:02<00:00, 56.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss: 0.7751607517764857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNN().cuda()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=1, reduction='sum') # Ignore the padding character\n",
    "\n",
    "for epoch in range(20):\n",
    "    losses = []\n",
    "    counts = 0\n",
    "    with tqdm(dataloader) as dataloader:\n",
    "        for batch in dataloader:\n",
    "            batch = batch[0].cuda()\n",
    "\n",
    "            hidden = model.initialize_hidden(len(batch)).cuda()\n",
    "            # Initialise the hidden state\n",
    "\n",
    "            loss = 0\n",
    "            counts = 0\n",
    "\n",
    "            for i in range(batch.shape[1]-1):\n",
    "                inpt = batch[:, i]\n",
    "                target = batch[:, i+1]\n",
    "                # The input character and the target character (next character)\n",
    "                # for each batch\n",
    "                # We are trying to predict the next character\n",
    "\n",
    "                output, hidden = model(inpt, hidden) # Pass the input and the hidden state\n",
    "                # This gives us a new hidden state and an output\n",
    "                loss += criterion(output, target)\n",
    "                counts += 1\n",
    "\n",
    "\n",
    "            losses.append(loss.item()/(counts*len(batch)))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "    # print(losses)\n",
    "    print(f\"Epoch {epoch} loss: {np.mean(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW:   aycelyn.\n",
      "FOUND: arnell.\n",
      "FOUND: julianna.\n",
      "NEW:   zyrel.\n",
      "NEW:   janil.\n",
      "FOUND: alexandria.\n",
      "NEW:   tradd.\n",
      "NEW:   rosavat.\n",
      "NEW:   elithyah.\n",
      "NEW:   anme.\n",
      "NEW:   macarion.\n",
      "NEW:   speles.\n",
      "FOUND: manvir.\n",
      "NEW:   kawauna.\n",
      "NEW:   lilyiann.\n",
      "FOUND: zyanna.\n",
      "NEW:   retha.\n",
      "FOUND: kamora.\n",
      "NEW:   eyanda.\n",
      "FOUND: kristan.\n"
     ]
    }
   ],
   "source": [
    "def sample_names():\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    for i in range(20):\n",
    "        hidden = model.initialize_hidden()\n",
    "        input = torch.tensor([0])\n",
    "        name = \"\"\n",
    "        for i in range(20):\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = torch.multinomial(F.softmax(output, dim=1), 1)\n",
    "            name += idx_to_str[input.item()]\n",
    "            if input.item() == 0:\n",
    "                break\n",
    "            input = torch.tensor([input])\n",
    "        if name.strip('.') in words:\n",
    "            print(\"FOUND:\", name)\n",
    "            continue\n",
    "        print(\"NEW:  \",name)\n",
    "\n",
    "sample_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32033/32033 [01:00<00:00, 532.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44988298416137695\n",
      "Loss: 1.7550740040874837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "        for name in dataset:\n",
    "            hidden = model.initialize_hidden()\n",
    "            loss = 0\n",
    "            counts = 0\n",
    "            for i in range(len(name)-1):\n",
    "                if name[i] == 0 and i > 0:\n",
    "                    break\n",
    "                input = torch.tensor([name[i]])\n",
    "                target = torch.tensor([name[i+1]])\n",
    "                output, hidden = model(input, hidden)\n",
    "                loss += F.cross_entropy(output, target)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += (pred == target).sum()\n",
    "                counts += 1\n",
    "                total += 1\n",
    "            losses.append(loss.item()/counts)\n",
    "            pbar.update(1)\n",
    "    print(f\"Accuracy: {correct/total}\")\n",
    "    print(f\"Loss: {np.mean(losses)}\")\n",
    "\n",
    "\n",
    "\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1f767b85a9ddfa74181083eaf2a0ca7790ab143097ab8c42db5e4f09d99ca78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
